{% extends "base.html" %}

{% block content %}
        <h1>О сервисе</h1>
<p>Этот сервис вычисляет семантическое сходство между словами русского языка (определяет степень их "квазисинонимии"). Он назван по аналогии с <a href="http://ruscorpora.ru/ru">RusCorpora</a>, веб-сайтом Национального Корпуса Русского Языка (НКРЯ). На <i>RusCorpora</i> можно работать с корпусами (лат. <i>corpora</i>), а на нашем ресурсе - с лексическими векторами (лат. <i>vectōrēs</i>).</p>
<p>В последнее время существенно возрос интерес к <a href="https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%81%D1%82%D1%80%D0%B8%D0%B1%D1%83%D1%82%D0%B8%D0%B2%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D0%BC%D0%B0%D0%BD%D1%82%D0%B8%D0%BA%D0%B0">дистрибутивной семантике</a>. В основном это обусловлено перспективностью подхода, использующего языковые модели на основе нейронных сетей, обученные на больших корпусах. При обучении мы получаем распределённые вектора для слов. Вероятно, самый известный на сегодня инструмент в этой области - <i><a href="https://code.google.com/p/word2vec/">word2vec</a></i>, позволяющий быстро получать вектора на огромных объёмах языкового материала.</p>
<blockquote><p><i>В дистрибутивной семантике слова обычно представляются в виде векторов в многомерном пространстве. Семантическое сходство вычисляется как простая <a href="https://en.wikipedia.org/wiki/Cosine_similarity">косинусная близость</a> между двумя векторами и может принимать значения в промежутке [0...1]. Значение <strong>0</strong> означает отсутствие похожих контекстов у этих слов, а <strong>1</strong> - напротив, свидетельствует о полной идентичности их контекстов.</i></p></blockquote>
<p><i>Word2vec</i> и подобные ему подходы подробно изучаются и тестируются в применении к английскому языку, в то время как для русского языка такая работа едва начата. Таким образом, важно предоставить русскоязычному лингвистическому сообществу доступ к соответствующим инструментам.</p>
<p>К сожалению, обучение и использование нейронных векторных моделей на основе больших корпусов может лежать за пределами возможностей домашних компьютеров и даже некоторых серверов. Вот почему мы создали этот сервис: мы хотим снизить порог входа для тех, кто хочет работать в этом новом и интересном направлении.</p>
<h2>Что такое <i>RusVectōrēs</i>?</h2>
<p><i>RusVectōrēs</i> - это семантический калькулятор, который работает с отношениями между словами в дистрибутивных моделях. Пользователь может выбрать одну или несколько моделей - в настоящий момент доступны <a href="/dsm/{{lang}}/models">4 модели</a>, обученные на разных корпусах (некоторые из них заняли ведущие места в <a href="http://russe.nlpub.ru/">соревновании RUSSE</a>). Каждая модель содержит от 200 тысяч до 1 миллиона лемм.</p>
<p>Выбрав модель, вы можете:</p>
<ol>
<li><a href="/dsm/{{lang}}/calculator">вычислять семантическое сходство</a> между парами слов;</li>
<li><a href="/dsm/{{lang}}/similar">находить слова, ближайшие к данному</a> (с возможностью фильтрации по части речи);</li>
<li><a href="/dsm/{{lang}}/similar">получать вектор (в виде массива чисел) данного слова в выбранной модели</a>;</li>
<li><a href="/dsm/{{lang}}/calculator">выполнять над векторами слов алгебраические операции </a> (сложение, вычитание, поиск центра лексического кластера и расстояний до этого центра).</li>
</ol>
<p>Последняя операция дает интересные результаты. Например, модель, обученная на русскоязычной Википедии и НКРЯ, возвращает слово <span style="color:green;"><i>быт</i></span> в результате вычитания слова <span style="color:green;"><i>смысл</i></span> из слова <span style="color:green;"><i>жизнь</i></span>. Это может показаться чем-то не слишком практичным, но исследования, уже проведенные для английского языка, доказали применимость таких отношений во многих областях, включая машинный перевод.</p>
<p>Естественно, можно сравнивать результаты разных моделей. Чтобы не ограничивать пользователей выбранными нами моделями, мы добавили возможность <a href="/dsm/{{lang}}/upload">загрузки своего корпуса</a>. Сервер обучит на нем модель <i>word2vec</i> с настройками, заданными пользователем.</p>
<blockquote><p><i>В духе парадигмы Semantic Web и Linked Data, каждое слово каждой модели обладает своим уникальным идентификатором URI, явно указывающим лемму, модель и часть речи (например, <a href="/dsm/{{lang}}/news/кризисный_A">http://ling.go.mail.ru/dsm/news/кризисный_A</a>). По запросу на этот адрес генерируется список десяти слов, ближайших к данной лемме в данной модели и принадлежащих к той же части речи, что и сама лемма.</i></p></blockquote>
<p>Нам бы хотелось, чтобы <i>RusVectōrēs</i> стал одним из узлов академической информации о нейронных языковых моделях для русского языка, поэтому на сайте имеется раздел <a href="/dsm/{{lang}}/publications">"Публикации"</a>, содержащий опубликованные научные работы и ссылки на другие полезные ресурсы. В то же время, мы надеемся, что <i>RusVectōrēs</i> популяризирует дистрибутивную семантику и компьютерную лингвистику и сделает их более доступными и привлекательными для русскоязычной публики.</p>
{% endblock %}